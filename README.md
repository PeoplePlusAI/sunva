# SUNVA AI : Solving conversation problem for the deaf

## About SUNVA AI

Having conversations with the deaf can be a challenge. While there are so many live transcription and text to speech tools available in the market, they are not catered for the needs of the deaf and hard to hearing. Mainly it takes a lot of time for the deaf person to read transcriptions and respond to them is a lo. SUNVA AI intelligently simplify and apply various filters on the transcriptions to minimize the amount of time taken to read transcription and switch gaze between the screen and the person.

## SUNVA AI workplan 

The [first version of the POC](https://www.figma.com/proto/xK0fvVJL9wRWTkwdBeRu2U/Sunva.Ai?page-id=84%3A803&node-id=84-805&viewport=917%2C520%2C0.14&t=ZpNPT9hGNjHWzrqy-1&scaling=min-zoom&content-scaling=fixed&starting-point-node-id=84%3A805&show-proto-sidebar=1) will have the following features along with speaker diarization and text to speech. 

1. Text simplification using LLM
2. Text highlighting using LLM
3. Intelligently apply simplification/highlighting to the transcriptions

Based on the user feedback from our focus group, we will refine and add more features to the POC.

## SUNVA AI Architecture

Please go through the [architecture diagram](https://www.figma.com/board/INrqk911VUw8uF29VrVnMw/Sunva-p1-flow-diagram?node-id=0-1&t=HF91DJzPwA6QnQT6-1) to understand how SUNVA AI works. Please raise your questions in the issues section if you have any.

## How to run POC

1. Clone the repository
2. Install the dependencies
```
pip install -r requirements.txt
```
3. Run the POC
```
streamlit run main.py
```

## How to contribute

There are few ways you can contribute to SUNVA AI.

1. By providing feedback on the POC
2. By raising issues in the issues section
3. By contributing to the codebase based on the issues
4. Join the SUNVA AI team by filling the [p+ai volunteer form](https://peopleplus.ai/volunteer) and select the SUNVA AI project.






